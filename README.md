# ğŸ¡ Home.LLC Data Engineering Assessment

This repository contains a complete data engineering pipeline for ingesting, validating, storing, and analyzing real estate-related data using MySQL, Python, and Docker.
---


## ğŸ“Œ Table of Contents

- [Project Overview](#project-overview)
- [Schema Design](#schema-design)
- [ETL Pipeline Design](#etl-pipeline-design)
- [Directory Structure](#directory-structure)
- [Setup & Installation](#setup--installation)
- [How to Run the ETL](#how-to-run-the-etl)
- [Assumptions & Design Decisions](#assumptions--design-decisions)
- [Known Issues & Improvements](#known-issues--improvements)
- [Author](#author)


## ğŸ“ Project Overview

**Objective:**  
Normalize a flat CSV dataset containing property information into a relational schema and develop a Python-based ETL pipeline to transform and load it into a MySQL database.

**Assessment Focus:**

- Data normalization  
- Relational schema design  
- ETL implementation  
- Clean code and documentation  

---

---
## ğŸ“ Project Structure

.
â”œâ”€â”€ analysis_outputs/           # Auto-generated plots and Excel reports
â”œâ”€â”€ docs/                       # Documentation (future expansion)
â”œâ”€â”€ normalized_csvs/           # Cleaned CSVs used in the ETL process
â”œâ”€â”€ scripts/                   # Python scripts
â”‚   â”œâ”€â”€ etl.py                 # ETL pipeline from CSV to MySQL
â”‚   â”œâ”€â”€ validate.py            # Data validation based on field config
â”‚   â””â”€â”€ analyze.py             # Data analysis and visualizations
â”œâ”€â”€ sql/                       # SQL schema and raw data
â”‚   â”œâ”€â”€ create_tables.sql      # SQL file to create normalized schema
â”‚   â”œâ”€â”€ fake_data.csv          # Raw source data
â”‚   â””â”€â”€ Field Config.xlsx      # Validation rules and expected types
â”œâ”€â”€ docker-compose.initial.yml # Docker config to spin up MySQL
â”œâ”€â”€ Dockerfile.initial_db      # Docker image definition
â”œâ”€â”€ .env                       # MySQL credentials (used in docker-compose)
â”œâ”€â”€ mismatch_report.xlsx       # Output from validation script
â”œâ”€â”€ README.md                  # You're here :)


## ğŸ› ï¸ Setup Instructions

Start MySQL with Docker
docker-compose -f docker-compose.initial.yml up -d

MySQL Credentials (from .env or docker-compose):
MYSQL_DATABASE = home_db
MYSQL_USER = db_user
MYSQL_PASSWORD = 6equj5_db_user
MYSQL_ROOT_PASSWORD = 6equj5_root

Create Database Schema
mysql -u root -p < sql/create_tables.sql

Run ETL
python scripts/etl.py

Run Validation
python scripts/validate.py

Run Analysis
python scripts/analyze.py

## ğŸ§© Database Schema

1. property (Primary table)
Primary Key: id

Stores all static property data such as location, type, year built, utilities, ratings, etc.

2. leads
Primary Key: id

Foreign Key: property_id â†’ property.id

Stores sales-related data: yield, IRR, seller info, occupancy.

3. valuation
Primary Key: id

Foreign Key: property_id â†’ property.id

Contains pricing estimates: ARV, Rent, Zestimate, Redfin values, etc.

4. rehab
Primary Key: id

Foreign Key: property_id â†’ property.id

Tracks rehabilitation estimates and boolean flags for components needing repairs.

5. hoa
Primary Key: id

Foreign Key: property_id â†’ property.id

Stores HOA-related info and flags.

6. taxes
Primary Key: id

Foreign Key: property_id â†’ property.id

Stores tax-related values.

## âœ… Validation Rules

Defined in Field Config.xlsx

Applied using validate.py

Checks include:

Required columns exist in the data

Data types match expectations (e.g., float, int, string, boolean)

Value ranges and missing values

Output is saved in mismatch_report.xlsx showing row-wise and field-wise issues.


## ğŸ“Š Analysis Performed
Stored in analysis_outputs/ and Excel sheet full_summary_report_detailed.xlsx.

Key Metrics:
Property Type counts

HOA presence and distribution

Reviewed Status & Lead Sources

Expected Rent:

Mean, Median, Max, Min

Distribution Plot

Taxes:

Mean, Max, Min, Std Dev

Rehab flag counts

Correlation heatmap between valuation features

Rent-to-ARV ratio for investment insights

## ğŸ“Œ Business Insights
Expected Rent varies from X to Y (see plots), with the average around Z

ARV vs Expected Rent correlation highlights underperforming investments

Rehab Flags provide insight into most common renovation needs (e.g., kitchen/bathroom)

Tax & HOA insights help filter profitable zip codes or areas

Valuation Correlation Matrix reveals relationships like:

High positive correlation: Expected_Rent â†” ARV

Useful for rental yield modeling






## ğŸ§± Schema Design

The raw CSV contains fields for properties, leads, valuations, rehabs, HOA data, and taxes. These were decomposed into normalized tables:

- `property`: Core property metadata  
- `leads`: Lead information linked to property  
- `valuation`: Estimated and actual values  
- `rehab`: Rehab estimates and flags  
- `hoa`: Homeowners Association details  
- `taxes`: Property tax values  

Each table is linked via a primary key `property_id` to maintain referential integrity.

---

## ğŸ” ETL Pipeline Design

The ETL pipeline is designed to perform the following operations:

1. **Extract**  
   Load the CSV file using `pandas`.

2. **Transform**  
   Clean NaNs, sanitize datatypes, split into normalized datasets.

3. **Load**  
   Insert records into corresponding MySQL tables using `mysql-connector-python`.

All transformations follow best practices for clarity, reusability, and performance.

---

## ğŸ“‚ Directory Structure

homellc_data_engineer_assessment_skeleton/
â”œâ”€â”€ docs/
â”‚ â””â”€â”€ images/
â”‚ â””â”€â”€ README.md
â”‚
â”œâ”€â”€ sql/
â”‚ â”œâ”€â”€ create_tables.sql
â”‚ â”œâ”€â”€ fake_data.csv
â”‚ â””â”€â”€ Field Config.xlsx
â”‚
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ etl.py
â”‚
â”œâ”€â”€ docker-compose.initial.yml
â”œâ”€â”€ docker-compose.final.yml
â”œâ”€â”€ Dockerfile.initial_db
â”œâ”€â”€ Dockerfile.final_db
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## âš™ï¸ Setup & Installation

### âœ… Prerequisites

- Python 3.9+
- Docker and Docker Compose
- MySQL client (optional, for inspection)

### ğŸ“¦ Install Dependencies

python -m venv venv
source venv/bin/activate (Windows: venv\Scripts\activate)
pip install -r requirements.txt


---

## ğŸš€ How to Run the ETL

### Step 1: Start MySQL via Docker

docker-compose -f docker-compose.initial.yml up --build -d


MySQL will be running on:

- Host: `127.0.0.1`  
- Port: `3306`  
- User: `root`  
- Password: `6equj5_root`  
- Database: `home_db`

### Step 2: Run the ETL Script

python scripts/etl.py


A successful run will print:

âœ… Data inserted into all tables.



---

## ğŸ§  Assumptions & Design Decisions

- One-to-one mapping assumed between property and other related entities in the CSV.
- Used `property_id` as a foreign key across all tables to maintain data integrity.
- Nullable values are handled using `None` in Python.
- Boolean fields normalized using flexible mappings (e.g., `yes`, `true`, `minimal flood`, etc.).
- Type casting is done explicitly using `applymap()` for consistency and error handling.

---

## ğŸ§° Known Issues & Improvements

- Add batch insert operations for performance scaling.
- Introduce structured logging and more granular exception handling.
- Implement schema validation using libraries like `Pydantic` or `Cerberus`.
- Add unit tests to validate ETL logic and transformations.

---

## ğŸ‘¨â€ğŸ’» Author

**Mayank Mathur**  
[LinkedIn Profile](https://www.linkedin.com/in/onlymayank11/)  
